{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('po2': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "82749e5b48c4d6085d7533a91d2fcb4730d08732f57a440b121b3ba77c8d61ee"
   }
  },
  "interpreter": {
   "hash": "8bb744c3983b83d7efd917b66d8c68559fdfd2886c0c86e50717b653eeaf4fc6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "'''\n",
    "02_filter-data.ipynb\n",
    "Filter the data for the analysis\n",
    "'''\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon\n",
    "from shapely.ops import nearest_points, cascaded_union\n",
    "import h3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PATH_ROOT = os.path.join(pathlib.Path().absolute(), '../..' )\n",
    "PATH_DATA_IN = PATH_ROOT + '/data/01_raw/'\n",
    "PATH_DATA_OUT = PATH_ROOT + '/data/02_processed/'\n",
    "\n",
    "\n",
    "os.makedirs(PATH_DATA_OUT) if not os.path.exists(PATH_DATA_OUT) else False"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "'''\n",
    "Filter activities table\n",
    "- Remove uncertain activities\n",
    "- Remove activities where PO2 was not presented\n",
    "'''\n",
    "\n",
    "PATH_ACTIVITIES_IN = PATH_DATA_IN + 'activities.csv'\n",
    "\n",
    "activities_all = pd.read_csv(PATH_ACTIVITIES_IN)\n",
    "\n",
    "# filter only activities with locality defined\n",
    "activities_all = activities_all[activities_all['lokalitat_name'].notnull()]\n",
    "\n",
    "# filter only certain activities\n",
    "activities_certain = activities_all[(activities_all['sicherheit'] == 1) | (activities_all['sicherheit'] == 2) | (activities_all['sicherheit'] == 3)]\n",
    "\n",
    "# get rid of all activities where po-ii was not presented \n",
    "activities_po_ii = activities_certain[(activities_certain['aussteller'] == 'M') | (activities_certain['aussteller'] == 'Ja') | (activities_certain['aussteller'] == '-')]\n",
    "\n",
    "print(len(activities_po_ii))\n",
    "\n",
    "# save only (for now) interesting columns\n",
    "activities_po_ii = activities_po_ii[['no', 'sicherheit', 'datum_text', 'tag_post','monat_post','jahr_post','tag_ante','monat_ante','jahr_ante', 'lokalitat_name','lokalitat_agglomeration', 'lokalitat_politik', 'bi1_lokalitatname', 'bi2_lokalitatname', 'bi3_lokalitatname', 'bi4_lokalitatname', 'bi5_lokalitatname', 'gg1_lokalitatname', 'gg2_lokalitatname', 'gg3_lokalitatname', 'gg4_lokalitatname', 'gg5_lokalitatname', 'aussteller']]\n",
    "\n",
    "# export table\n",
    "activities_po_ii.to_csv(PATH_DATA_OUT + 'activities.csv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "630\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# get list of unique localities from the table of filtered activities\n",
    "\n",
    "PATH_ACTIVITIES_IN = PATH_DATA_OUT + 'activities.csv'\n",
    "PATH_PLACES_IN = PATH_DATA_IN + 'localities.csv'\n",
    "\n",
    "activities = pd.read_csv(PATH_ACTIVITIES_IN)\n",
    "places_all = pd.read_csv(PATH_PLACES_IN)\n",
    "\n",
    "# add geometry attribute    \n",
    "places_all['geometry'] = places_all.apply(\n",
    "    lambda x: Point(x['y'], x['x']), axis=1\n",
    ")\n",
    "places_all = gpd.GeoDataFrame(places_all).set_geometry('geometry')\n",
    "\n",
    "# take only places that are listed in activities\n",
    "destination_names = activities['lokalitat_name'].unique()\n",
    "destinations = places_all[places_all['name'].isin(destination_names)]\n",
    "\n",
    "# save as .csv\n",
    "places_all.to_csv(PATH_DATA_OUT + 'localities.csv')\n",
    "destinations.to_csv(PATH_DATA_OUT + 'destinations.csv')\n",
    "\n",
    "# save as GeoJSON files also\n",
    "places_all.to_file(PATH_DATA_OUT + 'localities.geojson',  driver=\"GeoJSON\")\n",
    "destinations.to_file(PATH_DATA_OUT + 'destinations.geojson',  driver=\"GeoJSON\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# create bounding box from the list of destinations\n",
    "\n",
    "PATH_DESTINATIONS_IN = PATH_DATA_OUT + 'destinations.csv'\n",
    "destinations = pd.read_csv(PATH_DESTINATIONS_IN)\n",
    "\n",
    "destinations['geometry'] = destinations['geometry'].apply(wkt.loads)\n",
    "destinations_geo = gpd.GeoDataFrame(destinations)\n",
    "\n",
    "# extend the boundaries by BOUND_MARGIN parameter\n",
    "BOUND_MARGIN = 0.2\n",
    "dbb = destinations_geo.total_bounds\n",
    "dbb_polygon = Polygon([\n",
    "    [dbb[0] - BOUND_MARGIN, dbb[1] - BOUND_MARGIN], \n",
    "    [dbb[0] - BOUND_MARGIN, dbb[3] + BOUND_MARGIN], \n",
    "    [dbb[2] + BOUND_MARGIN, dbb[3] + BOUND_MARGIN], \n",
    "    [dbb[2] + BOUND_MARGIN, dbb[1] - BOUND_MARGIN], \n",
    "    [dbb[0] - BOUND_MARGIN, dbb[1] - BOUND_MARGIN]\n",
    "])\n",
    "bbox = gpd.GeoDataFrame([{'geometry': dbb_polygon}])\n",
    "bbox.to_file(PATH_DATA_OUT + 'bbox.geojson', driver=\"GeoJSON\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# clip srtm to the bounding box\n",
    "\n",
    "PATH_IN_SRTM = PATH_DATA_IN + 'srtm/merged.tif'\n",
    "PATH_OUT_SRTM = PATH_DATA_OUT + 'elevation.tif'\n",
    "\n",
    "print(PATH_IN_SRTM)\n",
    "\n",
    "if os.path.isfile(PATH_OUT_SRTM):\n",
    "    os.remove(PATH_OUT_SRTM)\n",
    "\n",
    "PATH_BBOX = PATH_DATA_OUT + 'bbox.geojson'\n",
    "bbox = gpd.read_file(PATH_BBOX)\n",
    "\n",
    "hex_distance = 2 * h3.edge_length(9)\n",
    "#hex_distance_grades = hex_distance / 111\n",
    "hex_distance_grades = 0.15\n",
    "\n",
    "bounds = bbox.total_bounds\n",
    "\n",
    "# clip_command = [\n",
    "#    \"rasterio\", \"clip\", PATH_IN_SRTM, PATH_OUT_SRTM, \"--bounds\", '\"20 40 25 45\"']\n",
    "# #subprocess.run(clip_command, capture_output=True)\n",
    "\n",
    "# # os.system(\"rasterio clip {} {} --bounds '{} {} {} {}'\".format(\n",
    "# #     PATH_IN_SRTM, PATH_OUT_SRTM, \n",
    "# #     bounds[0],bounds[1],bounds[2],bounds[3]\n",
    "# # ))\n",
    "\n",
    "os.system(\"gdalwarp -tr {} {} -te {} {} {} {} -t_srs EPSG:4326 -co COMPRESS=LZW -r min {} {}\".format(\n",
    "    hex_distance / 111, hex_distance / 111, \n",
    "    bounds[0], bounds[1], bounds[2], bounds[3],\n",
    "    PATH_IN_SRTM, PATH_OUT_SRTM\n",
    "))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/casus-fwu036/projects/itinerary-analysis_premysl-otakar/src/processing/../../data/01_raw/srtm/merged.tif\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# clip rivers to the bounding box\n",
    "\n",
    "PATH_RIVERS_IN = PATH_DATA_IN + 'rivers/rivers.geojson'\n",
    "PATH_BBOX = PATH_DATA_OUT + 'bbox.geojson'\n",
    "\n",
    "rivers = gpd.read_file(PATH_RIVERS_IN)\n",
    "bbox = gpd.read_file(PATH_BBOX)\n",
    "rivers_clip = gpd.clip(rivers, bbox)\n",
    "\n",
    "#print(rivers_clip)\n",
    "rivers_clip.to_file(PATH_DATA_OUT + 'rivers.geojson', driver=\"GeoJSON\")\n",
    "rivers_clip.plot()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# create a list of bridges\n",
    "\n",
    "CONST_distance_bridge = 12 / 111\n",
    "\n",
    "PATH_LOCALITIES_IN = PATH_DATA_OUT + 'localities.geojson'\n",
    "PATH_RIVERS_IN = PATH_DATA_OUT + 'rivers.geojson'\n",
    "\n",
    "# load all certain places\n",
    "places_all = gpd.read_file(PATH_LOCALITIES_IN)\n",
    "places_certain = places_all[places_all['prazision'] == 1]\n",
    "\n",
    "# load rivers\n",
    "rivers = gpd.read_file(PATH_RIVERS_IN)\n",
    "\n",
    "bridges_ps = []\n",
    "for si, stop in places_certain.iterrows():\n",
    "    if stop['geometry']:\n",
    "        stop_buffer = stop['geometry'].buffer(CONST_distance_bridge)\n",
    "        #print (stop_buffer)\n",
    "        for ri, river in rivers.iterrows():\n",
    "            if river['geometry'].crosses(stop_buffer):\n",
    "                bridge_p = nearest_points(stop['geometry'], river['geometry'])[1]\n",
    "                bridges_ps.append(bridge_p)\n",
    "\n",
    "#bridges = cascaded_union([b.buffer(hex_distance / 222) for b in bridges_ps])\n",
    "\n",
    "# export bridges\n",
    "bridges_gdf = gpd.GeoDataFrame([{\"geometry\": bridge} for bridge in bridges_ps], crs={'init': 'epsg:4326'}, geometry='geometry')\n",
    "bridges_gdf.to_file(PATH_DATA_OUT + 'bridges.geojson', driver='GeoJSON')\n",
    "\n",
    "bridges_gdf.plot()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}