{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('po2': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "82749e5b48c4d6085d7533a91d2fcb4730d08732f57a440b121b3ba77c8d61ee"
   }
  },
  "interpreter": {
   "hash": "8bb744c3983b83d7efd917b66d8c68559fdfd2886c0c86e50717b653eeaf4fc6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "'''\n",
    "03_create-paths.ipynb\n",
    "Create a dataset of shortest paths between all destinations\n",
    "'''\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "from shapely.ops import nearest_points, unary_union\n",
    "import math\n",
    "import swifter\n",
    "import json\n",
    "import geojson\n",
    "import h3\n",
    "import networkit as nk\n",
    "from osgeo import gdal\n",
    "\n",
    "PATH_ROOT = os.path.join(pathlib.Path().absolute(), '../..' )\n",
    "PATH_IN = PATH_ROOT + '/data/02_processed/'\n",
    "PATH_OUT = PATH_ROOT + '/data/03_paths/'\n",
    "os.makedirs(PATH_OUT) if not os.path.exists(PATH_OUT) else False\n",
    "\n",
    "# constants\n",
    "CONST_graph_detail_lvl = 8\n",
    "CONST_speed_day_km = 40\n",
    "CONST_slope_effect_multiplier = 2\n",
    "CONST_distance_bridge = 10 / 111\n",
    "CONST_river_value = 9999\n",
    "\n",
    "# critical slope algorithm\n",
    "CONST_critical_slope = 4\n",
    "\n",
    "# for tobler application\n",
    "CONST_elevation_coefficient = 1\n",
    "\n",
    "def slope_coeff(slope):\n",
    "    return 1 / (1 + ((abs(slope) * 100) / CONST_critical_slope) ** 2)\n",
    "\n",
    "def calculate_path_time(value_from, value_to, dist):\n",
    "    rise = (value_to - value_from) / 1000\n",
    "    if value_from == CONST_river_value and value_to == CONST_river_value:\n",
    "        return 10000\n",
    "    else:\n",
    "        slope = rise / dist\n",
    "        slope_c = slope_coeff(slope)\n",
    "        time = CONST_speed_day_km * abs(slope_c ** CONST_slope_effect_multiplier)\n",
    "\n",
    "        el_dist = math.sqrt((rise ** 2) + (dist ** 2))\n",
    "        path_time = (el_dist / time)\n",
    "\n",
    "        #print(value_to, value_from, slope, time, el_dist, path_time)\n",
    "        return path_time\n",
    "\n",
    "#print(calculate_path_time(100, 300, 2))\n",
    "#print(calculate_path_time(100, 200, 1))\n",
    "print(calculate_path_time(CONST_river_value, CONST_river_value, 10))\n",
    "print(calculate_path_time(50, 200, 40))\n",
    "print(calculate_path_time(200, 50, 40))\n",
    "\n",
    "hex_distance = 2 * h3.edge_length(CONST_graph_detail_lvl)\n",
    "print('hex_distance', hex_distance)\n",
    "\n",
    "# load datasets\n",
    "\n",
    "destinations = gpd.read_file(PATH_IN + 'destinations.geojson')\n",
    "\n",
    "rivers_df = gpd.read_file(PATH_IN + 'rivers.geojson') \n",
    "rivers = unary_union(\n",
    "    [river['geometry'] for ri, river in rivers_df.iterrows()]\n",
    ")\n",
    "\n",
    "bridges_df = gpd.read_file(PATH_IN + 'bridges.geojson')\n",
    "bridges = unary_union(\n",
    "    [bridge['geometry'].buffer(hex_distance / 222) for bi, bridge in bridges_df.iterrows()]\n",
    ")\n",
    "\n",
    "bbox = gpd.read_file(PATH_IN + 'bbox.geojson') \n",
    "bb_xy = bbox.total_bounds\n",
    "\n",
    "bounds_json = dict(\n",
    "    geojson.Polygon(\n",
    "        [[\n",
    "            [bb_xy[0], bb_xy[1]],\n",
    "            [bb_xy[0], bb_xy[3]],\n",
    "            [bb_xy[2], bb_xy[3]],\n",
    "            [bb_xy[2], bb_xy[1]],\n",
    "            [bb_xy[0], bb_xy[1]],\n",
    "        ]]\n",
    "    ))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10000\n",
      "1.017662527983812\n",
      "1.017662527983812\n",
      "hex_distance 0.922709368\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# load elevation\n",
    "elevation = gdal.Open(PATH_IN + 'elevation.tif')\n",
    "band = elevation.GetRasterBand(1)\n",
    "cols = elevation.RasterXSize\n",
    "rows = elevation.RasterYSize\n",
    "\n",
    "transform = elevation.GetGeoTransform()\n",
    "xOrigin = transform[0]\n",
    "yOrigin = transform[3]\n",
    "pixelWidth = transform[1]\n",
    "pixelHeight = -transform[5]\n",
    "\n",
    "elevation_data = band.ReadAsArray(0, 0, cols, rows)\n",
    "\n",
    "# check whether there is river or a bridge\n",
    "def path_value_point (hex_center):\n",
    "    #return elevation_point(hex_center)\n",
    "    #on_river = hex.intersects(rivers)\n",
    "    on_river = hex_center.distance(rivers) < hex_distance / 200\n",
    "    if on_river: \n",
    "        on_bridge = hex_center.distance(bridges) < hex_distance / 200\n",
    "        if not on_bridge:\n",
    "            value = CONST_river_value\n",
    "        else:\n",
    "            value = elevation_point(hex_center)\n",
    "    else:\n",
    "        value = elevation_point(hex_center)\n",
    "    return value\n",
    "\n",
    "# get elevation value for the given geographical point\n",
    "def elevation_point (point):\n",
    "    row = int((yOrigin - point.y ) / pixelHeight)\n",
    "    col = int((point.x - xOrigin) / pixelWidth)\n",
    "    \n",
    "    if elevation_data.shape[0] > row and elevation_data.shape[1] > col:\n",
    "        el_value = int(elevation_data[row][col])\n",
    "        if el_value <= 0: # sea\n",
    "            return CONST_river_value\n",
    "        else:\n",
    "            return el_value\n",
    "    else:\n",
    "        return CONST_river_value"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# construct hexes dataframe\n",
    "\n",
    "hex_ids = list(h3.polyfill(bounds_json, CONST_graph_detail_lvl))\n",
    "\n",
    "hexes_df = pd.DataFrame(hex_ids, columns=['id'])\n",
    "hexes_df['center'] = hexes_df.swifter.apply(\n",
    "    lambda x: Point(h3.h3_to_geo(x['id'])),\n",
    "    axis = 1\n",
    ")\n",
    "hexes_df[\"value\"] = hexes_df.swifter.apply(\n",
    "    lambda x: path_value_point(x['center']),\n",
    "    axis = 1\n",
    ")\n",
    "hexes_df.set_index('id', inplace=True)\n",
    "\n",
    "# find neighboring hexes\n",
    "hexes_df['neighbors'] = hexes_df.swifter.apply(\n",
    "    lambda x: \\\n",
    "        [\n",
    "            h3.get_destination_h3_index_from_unidirectional_edge(n) \n",
    "            for n in h3.get_h3_unidirectional_edges_from_hexagon(x.name)\\\n",
    "        ],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# save hexes_df\n",
    "hexes_df.to_csv(PATH_OUT + 'hexes.csv')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Dask Apply: 100%|██████████| 16/16 [00:33<00:00,  2.08s/it]\n",
      "Dask Apply: 100%|██████████| 16/16 [00:55<00:00,  3.49s/it]\n",
      "Pandas Apply: 100%|██████████| 1709641/1709641 [00:29<00:00, 57887.34it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "hexes_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      center  value  \\\n",
       "id                                                                    \n",
       "885240acd9fffff   POINT (17.8961824010076 51.25719386424838)    185   \n",
       "885256c637fffff  POINT (16.79759787357567 47.22245680002387)    177   \n",
       "885251c9bdfffff  POINT (16.27404624365018 48.95542206754432)    237   \n",
       "885260566dfffff  POINT (20.56098346523435 50.79819521510542)    226   \n",
       "8863adc0a3fffff   POINT (13.57264222972097 55.0287826928452)   9999   \n",
       "...                                                      ...    ...   \n",
       "88535a2831fffff  POINT (20.86569124443697 48.25892511831216)    225   \n",
       "8863a01999fffff  POINT (13.88838576022147 52.53377500903377)     68   \n",
       "8863849295fffff  POINT (12.77036712139547 52.23874374043172)     56   \n",
       "88520b7267fffff   POINT (16.5646954418298 46.30323703474963)    149   \n",
       "885249344dfffff  POINT (16.28305438643352 54.20765318510403)     22   \n",
       "\n",
       "                                                         neighbors  \n",
       "id                                                                  \n",
       "885240acd9fffff  [885241db65fffff, 885240acd1fffff, 885240acdbf...  \n",
       "885256c637fffff  [885256c633fffff, 885256c45dfffff, 885256c459f...  \n",
       "885251c9bdfffff  [885251c9abfffff, 885251c987fffff, 885251c9b9f...  \n",
       "885260566dfffff  [885260cdbbfffff, 885260cdb3fffff, 8852605665f...  \n",
       "8863adc0a3fffff  [8863adc0a1fffff, 8863adce49fffff, 8863adc0bdf...  \n",
       "...                                                            ...  \n",
       "88535a2831fffff  [88535a2835fffff, 88535a283bfffff, 88535a283df...  \n",
       "8863a01999fffff  [8863a01991fffff, 8863a018a5fffff, 8863a0199bf...  \n",
       "8863849295fffff  [8863849297fffff, 8863849291fffff, 88638492b9f...  \n",
       "88520b7267fffff  [88520b7263fffff, 88520b722dfffff, 88520b7261f...  \n",
       "885249344dfffff  [8852493627fffff, 8852493445fffff, 8852493449f...  \n",
       "\n",
       "[1709641 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>center</th>\n",
       "      <th>value</th>\n",
       "      <th>neighbors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>885240acd9fffff</th>\n",
       "      <td>POINT (17.8961824010076 51.25719386424838)</td>\n",
       "      <td>185</td>\n",
       "      <td>[885241db65fffff, 885240acd1fffff, 885240acdbf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885256c637fffff</th>\n",
       "      <td>POINT (16.79759787357567 47.22245680002387)</td>\n",
       "      <td>177</td>\n",
       "      <td>[885256c633fffff, 885256c45dfffff, 885256c459f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885251c9bdfffff</th>\n",
       "      <td>POINT (16.27404624365018 48.95542206754432)</td>\n",
       "      <td>237</td>\n",
       "      <td>[885251c9abfffff, 885251c987fffff, 885251c9b9f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885260566dfffff</th>\n",
       "      <td>POINT (20.56098346523435 50.79819521510542)</td>\n",
       "      <td>226</td>\n",
       "      <td>[885260cdbbfffff, 885260cdb3fffff, 8852605665f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8863adc0a3fffff</th>\n",
       "      <td>POINT (13.57264222972097 55.0287826928452)</td>\n",
       "      <td>9999</td>\n",
       "      <td>[8863adc0a1fffff, 8863adce49fffff, 8863adc0bdf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88535a2831fffff</th>\n",
       "      <td>POINT (20.86569124443697 48.25892511831216)</td>\n",
       "      <td>225</td>\n",
       "      <td>[88535a2835fffff, 88535a283bfffff, 88535a283df...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8863a01999fffff</th>\n",
       "      <td>POINT (13.88838576022147 52.53377500903377)</td>\n",
       "      <td>68</td>\n",
       "      <td>[8863a01991fffff, 8863a018a5fffff, 8863a0199bf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8863849295fffff</th>\n",
       "      <td>POINT (12.77036712139547 52.23874374043172)</td>\n",
       "      <td>56</td>\n",
       "      <td>[8863849297fffff, 8863849291fffff, 88638492b9f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88520b7267fffff</th>\n",
       "      <td>POINT (16.5646954418298 46.30323703474963)</td>\n",
       "      <td>149</td>\n",
       "      <td>[88520b7263fffff, 88520b722dfffff, 88520b7261f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885249344dfffff</th>\n",
       "      <td>POINT (16.28305438643352 54.20765318510403)</td>\n",
       "      <td>22</td>\n",
       "      <td>[8852493627fffff, 8852493445fffff, 8852493449f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1709641 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# create weighted non-directional graph for all combinations of neighboring hexes\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "hexes_df = gpd.read_file(\n",
    "    PATH_OUT + 'hexes.csv'\n",
    ")\n",
    "hexes_df['center'] = hexes_df['center'].apply(wkt.loads)\n",
    "hexes_df['neighbors'] = hexes_df['neighbors'].apply(literal_eval)\n",
    "hexes_df[\"value\"] = pd.to_numeric(hexes_df[\"value\"])\n",
    "hexes_df.set_index('id', inplace=True)\n",
    "\n",
    "g = nk.Graph(directed=False, weighted=True)\n",
    "\n",
    "hexes_df['node'] = hexes_df.apply(\n",
    "    lambda x: g.addNode(),\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# node_id -> hex_id shorthand dictionary\n",
    "node_to_hex = {node_id: hex_id for (hex_id, node_id) in hexes_df[['node']].itertuples()}\n",
    "\n",
    "for (hex_from_id, value_from, node_from, neighbors) in hexes_df[['value', 'node', 'neighbors']].itertuples():\n",
    "    for hex_to_id in neighbors:\n",
    "        if hex_to_id in hexes_df.index:\n",
    "            node_to = hexes_df.at[hex_to_id, 'node']\n",
    "            value_to = hexes_df.at[hex_to_id, 'value']\n",
    "            g.addEdge(node_from, node_to, calculate_path_time(value_from, value_to, hex_distance))\n",
    "\n",
    "g.indexEdges()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# run dijkstra algorithm for all destinations\n",
    "destinations['hex_id'] = destinations.apply(\n",
    "    lambda x: h3.geo_to_h3(x['geometry'].x, x['geometry'].y, CONST_graph_detail_lvl),\n",
    "    axis=1\n",
    ")\n",
    "destinations['node_id'] = destinations.apply(\n",
    "    lambda x: hexes_df.at[x['hex_id'], 'node'],\n",
    "    axis=1\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# calculate hex id for each destination\n",
    "\n",
    "paths = []\n",
    "\n",
    "for (id_from, name_from, hex_from, node_from) in destinations[['name', 'hex_id', 'node_id']].itertuples():\n",
    "\n",
    "    print('finding paths for destinations {}/{} ({}%)'.format(id_from, len(destinations), int(id_from / len(destinations) * 100)))\n",
    "\n",
    "    dij = nk.distance.Dijkstra(g, node_from, True, False)\n",
    "    dij.run()\n",
    "    for (id_to, name_to, hex_to, node_to) in destinations[['name', 'hex_id', 'node_id']].itertuples():\n",
    "         \n",
    "\n",
    "        dist = dij.distance(node_to)\n",
    "        path = dij.getPath(node_to)\n",
    "        path_hexes = LineString([hexes_df.at[node_to_hex[i], 'center'] for i in path])\n",
    "\n",
    "        paths.append(\n",
    "            {\n",
    "                \"from\": name_from,\n",
    "                \"to\": name_to,\n",
    "                \"dist\": dist,\n",
    "                \"geometry\": path_hexes\n",
    "            }\n",
    "        )\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "finding paths for destinations 0/126 (0%)\n",
      "finding paths for destinations 1/126 (0%)\n",
      "finding paths for destinations 2/126 (1%)\n",
      "finding paths for destinations 3/126 (2%)\n",
      "finding paths for destinations 4/126 (3%)\n",
      "finding paths for destinations 5/126 (3%)\n",
      "finding paths for destinations 6/126 (4%)\n",
      "finding paths for destinations 7/126 (5%)\n",
      "finding paths for destinations 8/126 (6%)\n",
      "finding paths for destinations 9/126 (7%)\n",
      "finding paths for destinations 10/126 (7%)\n",
      "finding paths for destinations 11/126 (8%)\n",
      "finding paths for destinations 12/126 (9%)\n",
      "finding paths for destinations 13/126 (10%)\n",
      "finding paths for destinations 14/126 (11%)\n",
      "finding paths for destinations 15/126 (11%)\n",
      "finding paths for destinations 16/126 (12%)\n",
      "finding paths for destinations 17/126 (13%)\n",
      "finding paths for destinations 18/126 (14%)\n",
      "finding paths for destinations 19/126 (15%)\n",
      "finding paths for destinations 20/126 (15%)\n",
      "finding paths for destinations 21/126 (16%)\n",
      "finding paths for destinations 22/126 (17%)\n",
      "finding paths for destinations 23/126 (18%)\n",
      "finding paths for destinations 24/126 (19%)\n",
      "finding paths for destinations 25/126 (19%)\n",
      "finding paths for destinations 26/126 (20%)\n",
      "finding paths for destinations 27/126 (21%)\n",
      "finding paths for destinations 28/126 (22%)\n",
      "finding paths for destinations 29/126 (23%)\n",
      "finding paths for destinations 30/126 (23%)\n",
      "finding paths for destinations 31/126 (24%)\n",
      "finding paths for destinations 32/126 (25%)\n",
      "finding paths for destinations 33/126 (26%)\n",
      "finding paths for destinations 34/126 (26%)\n",
      "finding paths for destinations 35/126 (27%)\n",
      "finding paths for destinations 36/126 (28%)\n",
      "finding paths for destinations 37/126 (29%)\n",
      "finding paths for destinations 38/126 (30%)\n",
      "finding paths for destinations 39/126 (30%)\n",
      "finding paths for destinations 40/126 (31%)\n",
      "finding paths for destinations 41/126 (32%)\n",
      "finding paths for destinations 42/126 (33%)\n",
      "finding paths for destinations 43/126 (34%)\n",
      "finding paths for destinations 44/126 (34%)\n",
      "finding paths for destinations 45/126 (35%)\n",
      "finding paths for destinations 46/126 (36%)\n",
      "finding paths for destinations 47/126 (37%)\n",
      "finding paths for destinations 48/126 (38%)\n",
      "finding paths for destinations 49/126 (38%)\n",
      "finding paths for destinations 50/126 (39%)\n",
      "finding paths for destinations 51/126 (40%)\n",
      "finding paths for destinations 52/126 (41%)\n",
      "finding paths for destinations 53/126 (42%)\n",
      "finding paths for destinations 54/126 (42%)\n",
      "finding paths for destinations 55/126 (43%)\n",
      "finding paths for destinations 56/126 (44%)\n",
      "finding paths for destinations 57/126 (45%)\n",
      "finding paths for destinations 58/126 (46%)\n",
      "finding paths for destinations 59/126 (46%)\n",
      "finding paths for destinations 60/126 (47%)\n",
      "finding paths for destinations 61/126 (48%)\n",
      "finding paths for destinations 62/126 (49%)\n",
      "finding paths for destinations 63/126 (50%)\n",
      "finding paths for destinations 64/126 (50%)\n",
      "finding paths for destinations 65/126 (51%)\n",
      "finding paths for destinations 66/126 (52%)\n",
      "finding paths for destinations 67/126 (53%)\n",
      "finding paths for destinations 68/126 (53%)\n",
      "finding paths for destinations 69/126 (54%)\n",
      "finding paths for destinations 70/126 (55%)\n",
      "finding paths for destinations 71/126 (56%)\n",
      "finding paths for destinations 72/126 (57%)\n",
      "finding paths for destinations 73/126 (57%)\n",
      "finding paths for destinations 74/126 (58%)\n",
      "finding paths for destinations 75/126 (59%)\n",
      "finding paths for destinations 76/126 (60%)\n",
      "finding paths for destinations 77/126 (61%)\n",
      "finding paths for destinations 78/126 (61%)\n",
      "finding paths for destinations 79/126 (62%)\n",
      "finding paths for destinations 80/126 (63%)\n",
      "finding paths for destinations 81/126 (64%)\n",
      "finding paths for destinations 82/126 (65%)\n",
      "finding paths for destinations 83/126 (65%)\n",
      "finding paths for destinations 84/126 (66%)\n",
      "finding paths for destinations 85/126 (67%)\n",
      "finding paths for destinations 86/126 (68%)\n",
      "finding paths for destinations 87/126 (69%)\n",
      "finding paths for destinations 88/126 (69%)\n",
      "finding paths for destinations 89/126 (70%)\n",
      "finding paths for destinations 90/126 (71%)\n",
      "finding paths for destinations 91/126 (72%)\n",
      "finding paths for destinations 92/126 (73%)\n",
      "finding paths for destinations 93/126 (73%)\n",
      "finding paths for destinations 94/126 (74%)\n",
      "finding paths for destinations 95/126 (75%)\n",
      "finding paths for destinations 96/126 (76%)\n",
      "finding paths for destinations 97/126 (76%)\n",
      "finding paths for destinations 98/126 (77%)\n",
      "finding paths for destinations 99/126 (78%)\n",
      "finding paths for destinations 100/126 (79%)\n",
      "finding paths for destinations 101/126 (80%)\n",
      "finding paths for destinations 102/126 (80%)\n",
      "finding paths for destinations 103/126 (81%)\n",
      "finding paths for destinations 104/126 (82%)\n",
      "finding paths for destinations 105/126 (83%)\n",
      "finding paths for destinations 106/126 (84%)\n",
      "finding paths for destinations 107/126 (84%)\n",
      "finding paths for destinations 108/126 (85%)\n",
      "finding paths for destinations 109/126 (86%)\n",
      "finding paths for destinations 110/126 (87%)\n",
      "finding paths for destinations 111/126 (88%)\n",
      "finding paths for destinations 112/126 (88%)\n",
      "finding paths for destinations 113/126 (89%)\n",
      "finding paths for destinations 114/126 (90%)\n",
      "finding paths for destinations 115/126 (91%)\n",
      "finding paths for destinations 116/126 (92%)\n",
      "finding paths for destinations 117/126 (92%)\n",
      "finding paths for destinations 118/126 (93%)\n",
      "finding paths for destinations 119/126 (94%)\n",
      "finding paths for destinations 120/126 (95%)\n",
      "finding paths for destinations 121/126 (96%)\n",
      "finding paths for destinations 122/126 (96%)\n",
      "finding paths for destinations 123/126 (97%)\n",
      "finding paths for destinations 124/126 (98%)\n",
      "finding paths for destinations 125/126 (99%)\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# export paths\n",
    "\n",
    "# load paths\n",
    "paths_df = gpd.GeoDataFrame(paths, crs=\"epsg:4326\")\n",
    "\n",
    "# simplify geometries\n",
    "paths_df['geometry'] = paths_df.apply(\n",
    "      lambda x: wkt.loads(\n",
    "          wkt.dumps(\n",
    "              x['geometry'].simplify(0.01, preserve_topology=True), \n",
    "              rounding_precision=3\n",
    "            )\n",
    "        ),\n",
    "      axis=1\n",
    "  )\n",
    "#paths_df.to_file(PATH_OUT + 'paths.shp', driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "paths_df.to_file(PATH_OUT + 'paths.geojson', driver=\"GeoJSON\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# create a destination metrix table\n",
    "\n",
    "paths_text = \"\".join([line.strip() for line in open(PATH_OUT + 'paths.geojson')])\n",
    "paths_dict = json.loads(paths_text)\n",
    "\n",
    "origins = {}\n",
    "for fi, feat in enumerate(paths_dict['features']):\n",
    "    orig = feat['properties']['from'] \n",
    "    origins[orig] = {'origin': orig}\n",
    "\n",
    "for fi, feat in enumerate(paths_dict['features']):\n",
    "    orig = feat['properties']['from']\n",
    "    dest = feat['properties']['to']\n",
    "    dist = feat['properties']['dist']\n",
    "    origins[orig][dest] = dist\n",
    "\n",
    "dist_df = pd.DataFrame(origins.values())\n",
    "\n",
    "\n",
    "dist_df.set_index('origin', inplace=True)\n",
    "dist_df.to_csv(PATH_OUT + 'dist_m.csv')\n",
    "\n",
    "print(dist_df.at['Brno', 'Praha'])\n",
    "print(dist_df.at['Praha', 'Brno'])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.298953769272481\n",
      "9.298953769272513\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  }
 ]
}