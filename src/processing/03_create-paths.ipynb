{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitpo2condab62bf3ef14774324bf08862b5f8a62c4",
   "display_name": "Python 3.8.2 64-bit ('po2': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "82749e5b48c4d6085d7533a91d2fcb4730d08732f57a440b121b3ba77c8d61ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3252929369373301\n",
      "0.3252929369373301\n",
      "hex_distance 0.922709368\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "03_create-paths.ipynb\n",
    "Create a dataset of shortest paths between all destinations\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import urllib.request\n",
    "import pathlib\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "from shapely.ops import nearest_points, unary_union\n",
    "import math\n",
    "import swifter\n",
    "\n",
    "import json\n",
    "import geojson\n",
    "import gdal\n",
    "import h3\n",
    "\n",
    "import networkit as nk\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "PATH_ROOT = os.path.join(pathlib.Path().absolute(), '../..' )\n",
    "PATH_IN = PATH_ROOT + '/data/02_processed/'\n",
    "PATH_OUT = PATH_ROOT + '/data/03_paths/'\n",
    "\n",
    "# constants\n",
    "CONST_graph_detail_lvl = 8\n",
    "CONST_speed_day_km = 40\n",
    "CONST_slope_effect_multiplier = 2\n",
    "CONST_distance_bridge = 10 / 111\n",
    "CONST_river_value = 9999\n",
    "\n",
    "# critical slope algorithm\n",
    "CONST_critical_slope = 4\n",
    "\n",
    "# for tobler application\n",
    "CONST_elevation_coefficient = 1\n",
    "\n",
    "def slope_coeff(slope):\n",
    "    #return math.exp(-3.5 * abs(slope + 0.05)) ** CONST_elevation_coefficient\n",
    "    #rise = (value_to - value_from) / 1000\n",
    "    #slope = rise / hex_distance\n",
    "    return 1 / (1 + ((abs(slope) * 100) / CONST_critical_slope) ** 2)\n",
    "\n",
    "def calculate_path_time(value_from, value_to, dist):\n",
    "    rise = (value_to - value_from) / 1000\n",
    "    slope = rise / dist\n",
    "    slope_c = slope_coeff(slope)\n",
    "    #print(slope_c)\n",
    "    time = CONST_speed_day_km * abs(slope_c ** CONST_slope_effect_multiplier)\n",
    "\n",
    "    el_dist = math.sqrt((rise ** 2) + (dist ** 2))\n",
    "    path_time = (el_dist / time)\n",
    "\n",
    "    #print(value_to, value_from, slope, time, el_dist, path_time)\n",
    "    \n",
    "    return path_time\n",
    "\n",
    "#print(calculate_path_time(100, 300, 2))\n",
    "#print(calculate_path_time(100, 200, 1))\n",
    "print(calculate_path_time(50, 200, 10))\n",
    "print(calculate_path_time(200, 50, 10))\n",
    "\n",
    "crs4326 = {'init': 'epsg:4326'}\n",
    "hex_distance = 2 * h3.edge_length(CONST_graph_detail_lvl)\n",
    "print('hex_distance', hex_distance)\n",
    "\n",
    "# get distance of hexes in grades\n",
    "CONST_hex_dist = hex_distance / 111\n",
    "\n",
    "'''\n",
    "Load datasets\n",
    "'''\n",
    "\n",
    "destinations = gpd.read_file(PATH_IN + 'destinations.geojson')\n",
    "\n",
    "rivers_df = gpd.read_file(PATH_IN + 'rivers.geojson') \n",
    "rivers = unary_union(\n",
    "    [river['geometry'] for ri, river in rivers_df.iterrows()]\n",
    ")\n",
    "\n",
    "bridges_df = gpd.read_file(PATH_IN + 'bridges.geojson')\n",
    "bridges = unary_union(\n",
    "    [bridge['geometry'].buffer(hex_distance / 222) for bi, bridge in bridges_df.iterrows()]\n",
    ")\n",
    "\n",
    "bbox = gpd.read_file(PATH_IN + 'bbox.geojson') \n",
    "bb_xy = bbox.total_bounds\n",
    "\n",
    "bounds_json = dict(\n",
    "    geojson.Polygon(\n",
    "        [[\n",
    "            [bb_xy[0], bb_xy[1]],\n",
    "            [bb_xy[0], bb_xy[3]],\n",
    "            [bb_xy[2], bb_xy[3]],\n",
    "            [bb_xy[2], bb_xy[1]],\n",
    "            [bb_xy[0], bb_xy[1]],\n",
    "        ]]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load elevation\n",
    "\n",
    "elevation = gdal.Open(PATH_IN + 'elevation.tif')\n",
    "band = elevation.GetRasterBand(1)\n",
    "cols = elevation.RasterXSize\n",
    "rows = elevation.RasterYSize\n",
    "\n",
    "transform = elevation.GetGeoTransform()\n",
    "xOrigin = transform[0]\n",
    "yOrigin = transform[3]\n",
    "pixelWidth = transform[1]\n",
    "pixelHeight = -transform[5]\n",
    "\n",
    "elevation_data = band.ReadAsArray(0, 0, cols, rows)\n",
    "\n",
    "# check whether there is river or a bridge\n",
    "def path_value_point (hex_center):\n",
    "    #return elevation_point(hex_center)\n",
    "    #on_river = hex.intersects(rivers)\n",
    "    on_river = hex_center.distance(rivers) < CONST_hex_dist / 2\n",
    "    if on_river: \n",
    "        on_bridge = hex_center.distance(bridges) < CONST_hex_dist / 2\n",
    "        if not on_bridge:\n",
    "            value = CONST_river_value\n",
    "        else:\n",
    "            value = elevation_point(hex_center)\n",
    "    else:\n",
    "        value = elevation_point(hex_center)\n",
    "    return value\n",
    "\n",
    "# get elevation value for the given geographical point\n",
    "def elevation_point (point):\n",
    "    row = int((yOrigin - point.y ) / pixelHeight)\n",
    "    col = int((point.x - xOrigin) / pixelWidth)\n",
    "    \n",
    "    if elevation_data.shape[0] > row and elevation_data.shape[1] > col:\n",
    "        el_value = int(elevation_data[row][col])\n",
    "        if el_value <= 0: # sea\n",
    "            return CONST_river_value\n",
    "        else:\n",
    "            return el_value\n",
    "    else:\n",
    "        return CONST_river_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Pandas Apply: 100%|██████████| 1711237/1711237 [01:23<00:00, 20616.54it/s]\n",
      "Pandas Apply: 100%|██████████| 1711237/1711237 [05:09<00:00, 5530.55it/s]\n",
      "Pandas Apply: 100%|██████████| 1711237/1711237 [02:07<00:00, 13391.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# construct hexes dataframe\n",
    "\n",
    "hex_ids = list(h3.polyfill(bounds_json, CONST_graph_detail_lvl))\n",
    "\n",
    "hexes_df = pd.DataFrame(hex_ids, columns=['id'])\n",
    "hexes_df['center'] = hexes_df.swifter.apply(\n",
    "    lambda x: Point(h3.h3_to_geo(x['id'])),\n",
    "    axis = 1\n",
    ")\n",
    "hexes_df[\"value\"] = hexes_df.swifter.apply(\n",
    "    lambda x: path_value_point(x['center']),\n",
    "    axis = 1\n",
    ")\n",
    "hexes_df.set_index('id', inplace=True)\n",
    "\n",
    "# find neighboring hexes\n",
    "hexes_df['neighbors'] = hexes_df.swifter.apply(\n",
    "    lambda x: \\\n",
    "        [\n",
    "            h3.get_destination_h3_index_from_unidirectional_edge(n) \n",
    "            for n in h3.get_h3_unidirectional_edges_from_hexagon(x.name)\\\n",
    "        ],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# save hexes_df\n",
    "hexes_df.to_csv(PATH_OUT + 'hexes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      center  value  \\\n",
       "id                                                                    \n",
       "8863abc46dfffff   POINT (11.98753205650361 54.6062090099005)      0   \n",
       "885243744bfffff  POINT (16.63318451837275 51.12748356732553)    133   \n",
       "8863120921fffff  POINT (14.35346628184218 54.06483614073171)      0   \n",
       "88525078a5fffff  POINT (16.02774787360705 48.25449179193012)    222   \n",
       "8843b232a9fffff  POINT (21.13037741250674 53.95912358150742)    140   \n",
       "...                                                      ...    ...   \n",
       "885240c205fffff   POINT (18.08612404648967 50.5061869149276)    227   \n",
       "8852564acdfffff  POINT (16.33577573641552 46.98197703675595)   9999   \n",
       "8852440357fffff  POINT (18.85013231874983 50.54521500297682)    294   \n",
       "8863a2b8e7fffff  POINT (13.34503156747253 52.17901731590549)     37   \n",
       "88526d8f1dfffff  POINT (20.20428308214483 53.98675700728156)     99   \n",
       "\n",
       "                                                         neighbors  \n",
       "id                                                                  \n",
       "8863abc46dfffff  [8863abc717fffff, 8863abc733fffff, 8863abc469f...  \n",
       "885243744bfffff  [8852437637fffff, 885243745dfffff, 8852437441f...  \n",
       "8863120921fffff  [8863120929fffff, 8863120927fffff, 886312092df...  \n",
       "88525078a5fffff  [88525078a7fffff, 88525078a1fffff, 88525079d3f...  \n",
       "8843b232a9fffff  [8843b23285fffff, 8843b232a1fffff, 8843b232e3f...  \n",
       "...                                                            ...  \n",
       "885240c205fffff  [885240c207fffff, 885240c229fffff, 885240c201f...  \n",
       "8852564acdfffff  [8852564127fffff, 8852564ac9fffff, 8852564a1bf...  \n",
       "8852440357fffff  [8852440319fffff, 885244030bfffff, 8852440355f...  \n",
       "8863a2b8e7fffff  [8863a2b8adfffff, 8863a2b8e1fffff, 8863a2b8e5f...  \n",
       "88526d8f1dfffff  [88526d8f11fffff, 88526d8f15fffff, 88526d8f0bf...  \n",
       "\n",
       "[1711237 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>center</th>\n      <th>value</th>\n      <th>neighbors</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8863abc46dfffff</th>\n      <td>POINT (11.98753205650361 54.6062090099005)</td>\n      <td>0</td>\n      <td>[8863abc717fffff, 8863abc733fffff, 8863abc469f...</td>\n    </tr>\n    <tr>\n      <th>885243744bfffff</th>\n      <td>POINT (16.63318451837275 51.12748356732553)</td>\n      <td>133</td>\n      <td>[8852437637fffff, 885243745dfffff, 8852437441f...</td>\n    </tr>\n    <tr>\n      <th>8863120921fffff</th>\n      <td>POINT (14.35346628184218 54.06483614073171)</td>\n      <td>0</td>\n      <td>[8863120929fffff, 8863120927fffff, 886312092df...</td>\n    </tr>\n    <tr>\n      <th>88525078a5fffff</th>\n      <td>POINT (16.02774787360705 48.25449179193012)</td>\n      <td>222</td>\n      <td>[88525078a7fffff, 88525078a1fffff, 88525079d3f...</td>\n    </tr>\n    <tr>\n      <th>8843b232a9fffff</th>\n      <td>POINT (21.13037741250674 53.95912358150742)</td>\n      <td>140</td>\n      <td>[8843b23285fffff, 8843b232a1fffff, 8843b232e3f...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>885240c205fffff</th>\n      <td>POINT (18.08612404648967 50.5061869149276)</td>\n      <td>227</td>\n      <td>[885240c207fffff, 885240c229fffff, 885240c201f...</td>\n    </tr>\n    <tr>\n      <th>8852564acdfffff</th>\n      <td>POINT (16.33577573641552 46.98197703675595)</td>\n      <td>9999</td>\n      <td>[8852564127fffff, 8852564ac9fffff, 8852564a1bf...</td>\n    </tr>\n    <tr>\n      <th>8852440357fffff</th>\n      <td>POINT (18.85013231874983 50.54521500297682)</td>\n      <td>294</td>\n      <td>[8852440319fffff, 885244030bfffff, 8852440355f...</td>\n    </tr>\n    <tr>\n      <th>8863a2b8e7fffff</th>\n      <td>POINT (13.34503156747253 52.17901731590549)</td>\n      <td>37</td>\n      <td>[8863a2b8adfffff, 8863a2b8e1fffff, 8863a2b8e5f...</td>\n    </tr>\n    <tr>\n      <th>88526d8f1dfffff</th>\n      <td>POINT (20.20428308214483 53.98675700728156)</td>\n      <td>99</td>\n      <td>[88526d8f11fffff, 88526d8f15fffff, 88526d8f0bf...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1711237 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "hexes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create weighted non-directional graph for all combinations of neighboring hexes\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "hexes_df = gpd.read_file(\n",
    "    PATH_OUT + 'hexes.csv'\n",
    ")\n",
    "hexes_df['center'] = hexes_df['center'].apply(wkt.loads)\n",
    "hexes_df['neighbors'] = hexes_df['neighbors'].apply(literal_eval)\n",
    "hexes_df[\"value\"] = pd.to_numeric(hexes_df[\"value\"])\n",
    "hexes_df.set_index('id', inplace=True)\n",
    "\n",
    "g = nk.Graph(directed=False, weighted=True)\n",
    "\n",
    "hexes_df['node'] = hexes_df.apply(\n",
    "    lambda x: g.addNode(),\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# node_id -> hex_id shorthand dictionary\n",
    "node_to_hex = {node_id: hex_id for (hex_id, node_id) in hexes_df[['node']].itertuples()}\n",
    "\n",
    "for (hex_from_id, value_from, node_from, neighbors) in hexes_df[['value', 'node', 'neighbors']].itertuples():\n",
    "    for hex_to_id in neighbors:\n",
    "        if hex_to_id in hexes_df.index:\n",
    "            node_to = hexes_df.at[hex_to_id, 'node']\n",
    "            value_to = hexes_df.at[hex_to_id, 'value']\n",
    "            g.addEdge(node_from, node_to, calculate_path_time(value_from, value_to, hex_distance))\n",
    "\n",
    "g.indexEdges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run dijkstra algorithm for all destinations\n",
    "\n",
    "destinations['hex_id'] = destinations.apply(\n",
    "    lambda x: h3.geo_to_h3(x['geometry'].x, x['geometry'].y, CONST_graph_detail_lvl),\n",
    "    axis=1\n",
    ")\n",
    "destinations['node_id'] = destinations.apply(\n",
    "    lambda x: hexes_df.at[x['hex_id'], 'node'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# def calculate_paths(hex_id):\n",
    "#     dij = nk.distance.Dijkstra(g, hexes_df.at[hex_id, 'node'], True, False)\n",
    "#     dij.run()\n",
    "#     return dij\n",
    "\n",
    "# destinations['dij'] = destinations.swifter.apply(\n",
    "#     lambda x: calculate_paths(x['hex_id']),\n",
    "#     axis=1\n",
    "# )\n",
    "#destinations.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "finding paths for destinations 0/132 (0%)\n",
      "finding paths for destinations 1/132 (0%)\n",
      "finding paths for destinations 2/132 (1%)\n",
      "finding paths for destinations 3/132 (2%)\n",
      "finding paths for destinations 4/132 (3%)\n",
      "finding paths for destinations 5/132 (3%)\n",
      "finding paths for destinations 6/132 (4%)\n",
      "finding paths for destinations 7/132 (5%)\n",
      "finding paths for destinations 8/132 (6%)\n",
      "finding paths for destinations 9/132 (6%)\n",
      "finding paths for destinations 10/132 (7%)\n",
      "finding paths for destinations 11/132 (8%)\n",
      "finding paths for destinations 12/132 (9%)\n",
      "finding paths for destinations 13/132 (9%)\n",
      "finding paths for destinations 14/132 (10%)\n",
      "finding paths for destinations 15/132 (11%)\n",
      "finding paths for destinations 16/132 (12%)\n",
      "finding paths for destinations 17/132 (12%)\n",
      "finding paths for destinations 18/132 (13%)\n",
      "finding paths for destinations 19/132 (14%)\n",
      "finding paths for destinations 20/132 (15%)\n",
      "finding paths for destinations 21/132 (15%)\n",
      "finding paths for destinations 22/132 (16%)\n",
      "finding paths for destinations 23/132 (17%)\n",
      "finding paths for destinations 24/132 (18%)\n",
      "finding paths for destinations 25/132 (18%)\n",
      "finding paths for destinations 26/132 (19%)\n",
      "finding paths for destinations 27/132 (20%)\n",
      "finding paths for destinations 28/132 (21%)\n",
      "finding paths for destinations 29/132 (21%)\n",
      "finding paths for destinations 30/132 (22%)\n",
      "finding paths for destinations 31/132 (23%)\n",
      "finding paths for destinations 32/132 (24%)\n",
      "finding paths for destinations 33/132 (25%)\n",
      "finding paths for destinations 34/132 (25%)\n",
      "finding paths for destinations 35/132 (26%)\n",
      "finding paths for destinations 36/132 (27%)\n",
      "finding paths for destinations 37/132 (28%)\n",
      "finding paths for destinations 38/132 (28%)\n",
      "finding paths for destinations 39/132 (29%)\n",
      "finding paths for destinations 40/132 (30%)\n",
      "finding paths for destinations 41/132 (31%)\n",
      "finding paths for destinations 42/132 (31%)\n",
      "finding paths for destinations 43/132 (32%)\n",
      "finding paths for destinations 44/132 (33%)\n",
      "finding paths for destinations 45/132 (34%)\n",
      "finding paths for destinations 46/132 (34%)\n",
      "finding paths for destinations 47/132 (35%)\n",
      "finding paths for destinations 48/132 (36%)\n",
      "finding paths for destinations 49/132 (37%)\n",
      "finding paths for destinations 50/132 (37%)\n",
      "finding paths for destinations 51/132 (38%)\n",
      "finding paths for destinations 52/132 (39%)\n",
      "finding paths for destinations 53/132 (40%)\n",
      "finding paths for destinations 54/132 (40%)\n",
      "finding paths for destinations 55/132 (41%)\n",
      "finding paths for destinations 56/132 (42%)\n",
      "finding paths for destinations 57/132 (43%)\n",
      "finding paths for destinations 58/132 (43%)\n",
      "finding paths for destinations 59/132 (44%)\n",
      "finding paths for destinations 60/132 (45%)\n",
      "finding paths for destinations 61/132 (46%)\n",
      "finding paths for destinations 62/132 (46%)\n",
      "finding paths for destinations 63/132 (47%)\n",
      "finding paths for destinations 64/132 (48%)\n",
      "finding paths for destinations 65/132 (49%)\n",
      "finding paths for destinations 66/132 (50%)\n",
      "finding paths for destinations 67/132 (50%)\n",
      "finding paths for destinations 68/132 (51%)\n",
      "finding paths for destinations 69/132 (52%)\n",
      "finding paths for destinations 70/132 (53%)\n",
      "finding paths for destinations 71/132 (53%)\n",
      "finding paths for destinations 72/132 (54%)\n",
      "finding paths for destinations 73/132 (55%)\n",
      "finding paths for destinations 74/132 (56%)\n",
      "finding paths for destinations 75/132 (56%)\n",
      "finding paths for destinations 76/132 (57%)\n",
      "finding paths for destinations 77/132 (58%)\n",
      "finding paths for destinations 78/132 (59%)\n",
      "finding paths for destinations 79/132 (59%)\n",
      "finding paths for destinations 80/132 (60%)\n",
      "finding paths for destinations 81/132 (61%)\n",
      "finding paths for destinations 82/132 (62%)\n",
      "finding paths for destinations 83/132 (62%)\n",
      "finding paths for destinations 84/132 (63%)\n",
      "finding paths for destinations 85/132 (64%)\n",
      "finding paths for destinations 86/132 (65%)\n",
      "finding paths for destinations 87/132 (65%)\n",
      "finding paths for destinations 88/132 (66%)\n",
      "finding paths for destinations 89/132 (67%)\n",
      "finding paths for destinations 90/132 (68%)\n",
      "finding paths for destinations 91/132 (68%)\n",
      "finding paths for destinations 92/132 (69%)\n",
      "finding paths for destinations 93/132 (70%)\n",
      "finding paths for destinations 94/132 (71%)\n",
      "finding paths for destinations 95/132 (71%)\n",
      "finding paths for destinations 96/132 (72%)\n",
      "finding paths for destinations 97/132 (73%)\n",
      "finding paths for destinations 98/132 (74%)\n",
      "finding paths for destinations 99/132 (75%)\n",
      "finding paths for destinations 100/132 (75%)\n",
      "finding paths for destinations 101/132 (76%)\n",
      "finding paths for destinations 102/132 (77%)\n",
      "finding paths for destinations 103/132 (78%)\n",
      "finding paths for destinations 104/132 (78%)\n",
      "finding paths for destinations 105/132 (79%)\n",
      "finding paths for destinations 106/132 (80%)\n",
      "finding paths for destinations 107/132 (81%)\n",
      "finding paths for destinations 108/132 (81%)\n",
      "finding paths for destinations 109/132 (82%)\n",
      "finding paths for destinations 110/132 (83%)\n",
      "finding paths for destinations 111/132 (84%)\n",
      "finding paths for destinations 112/132 (84%)\n",
      "finding paths for destinations 113/132 (85%)\n",
      "finding paths for destinations 114/132 (86%)\n",
      "finding paths for destinations 115/132 (87%)\n",
      "finding paths for destinations 116/132 (87%)\n",
      "finding paths for destinations 117/132 (88%)\n",
      "finding paths for destinations 118/132 (89%)\n",
      "finding paths for destinations 119/132 (90%)\n",
      "finding paths for destinations 120/132 (90%)\n",
      "finding paths for destinations 121/132 (91%)\n",
      "finding paths for destinations 122/132 (92%)\n",
      "finding paths for destinations 123/132 (93%)\n",
      "finding paths for destinations 124/132 (93%)\n",
      "finding paths for destinations 125/132 (94%)\n",
      "finding paths for destinations 126/132 (95%)\n",
      "finding paths for destinations 127/132 (96%)\n",
      "finding paths for destinations 128/132 (96%)\n",
      "finding paths for destinations 129/132 (97%)\n",
      "finding paths for destinations 130/132 (98%)\n",
      "finding paths for destinations 131/132 (99%)\n"
     ]
    }
   ],
   "source": [
    "# calculate hex id for each destination\n",
    "\n",
    "paths = []\n",
    "\n",
    "for (id_from, name_from, hex_from, node_from) in destinations[['name', 'hex_id', 'node_id']].itertuples():\n",
    "\n",
    "    print('finding paths for destinations {}/{} ({}%)'.format(id_from, len(destinations), int(id_from / len(destinations) * 100)))\n",
    "\n",
    "    dij = nk.distance.Dijkstra(g, node_from, True, False)\n",
    "    dij.run()\n",
    "    for (id_to, name_to, hex_to, node_to) in destinations[['name', 'hex_id', 'node_id']].itertuples():\n",
    "         \n",
    "\n",
    "        dist = dij.distance(node_to)\n",
    "        path = dij.getPath(node_to)\n",
    "        path_hexes = LineString([hexes_df.at[node_to_hex[i], 'center'] for i in path])\n",
    "\n",
    "        paths.append(\n",
    "            {\n",
    "                \"from\": name_from,\n",
    "                \"to\": name_to,\n",
    "                \"dist\": dist,\n",
    "                \"geometry\": path_hexes\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:fiona._env:/home/adam/projects/itinerary-analysis_premysl-otakar/src/processing/../../data/03_paths/paths.geojson: No such file or directory\n",
      "WARNING:fiona._env:driver GeoJSON does not support creation option ENCODING\n"
     ]
    }
   ],
   "source": [
    "# export paths\n",
    "\n",
    "paths_df = gpd.GeoDataFrame(paths, crs=\"epsg:4326\")\n",
    "# simplify geometries\n",
    "paths_df['geometry'] = paths_df.apply(\n",
    "      lambda x: wkt.loads(\n",
    "          wkt.dumps(\n",
    "              x['geometry'].simplify(0.01, preserve_topology=True), \n",
    "              rounding_precision=3\n",
    "            )\n",
    "        ),\n",
    "      axis=1\n",
    "  )\n",
    "#paths_df.to_file(PATH_OUT + 'paths.shp', driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "paths_df.to_file(PATH_OUT + 'paths.geojson', driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9.614468463881705\n9.614468463881702\n"
     ]
    }
   ],
   "source": [
    "# create a destination metrix table\n",
    "\n",
    "paths_text = \"\".join([line.strip() for line in open(PATH_OUT + 'paths.geojson')])\n",
    "paths_dict = json.loads(paths_text)\n",
    "\n",
    "origins = {}\n",
    "for fi, feat in enumerate(paths_dict['features']):\n",
    "    orig = feat['properties']['from'] \n",
    "    origins[orig] = {'origin': orig}\n",
    "\n",
    "for fi, feat in enumerate(paths_dict['features']):\n",
    "    orig = feat['properties']['from']\n",
    "    dest = feat['properties']['to']\n",
    "    dist = feat['properties']['dist']\n",
    "    origins[orig][dest] = dist\n",
    "\n",
    "dist_df = pd.DataFrame(origins.values())\n",
    "\n",
    "\n",
    "dist_df.set_index('origin', inplace=True)\n",
    "dist_df.to_csv(PATH_OUT + 'dist_m.csv')\n",
    "\n",
    "print(dist_df.at['Brno', 'Praha'])\n",
    "print(dist_df.at['Praha', 'Brno'])\n"
   ]
  }
 ]
}