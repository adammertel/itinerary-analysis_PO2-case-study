{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bitpo2conda0cc6c94dcc774996989d8c0ab52f6b64",
   "display_name": "Python 3.8.2 64-bit ('po2': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "82749e5b48c4d6085d7533a91d2fcb4730d08732f57a440b121b3ba77c8d61ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0044064213843935\n1.0044064213843935\nhex_distance 0.922709368\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "03_create-paths.ipynb\n",
    "Create a dataset of shortest paths between all destinations\n",
    "'''\n",
    "\n",
    "import requests\n",
    "import pathlib\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "from shapely.ops import nearest_points, unary_union\n",
    "import math\n",
    "import swifter\n",
    "import json\n",
    "import geojson\n",
    "import gdal\n",
    "import h3\n",
    "import networkit as nk\n",
    "\n",
    "PATH_ROOT = os.path.join(pathlib.Path().absolute(), '../..' )\n",
    "PATH_IN = PATH_ROOT + '/data/02_processed/'\n",
    "PATH_OUT = PATH_ROOT + '/data/03_paths/'\n",
    "\n",
    "# constants\n",
    "CONST_graph_detail_lvl = 8\n",
    "CONST_speed_day_km = 40\n",
    "CONST_slope_effect_multiplier = 2\n",
    "CONST_distance_bridge = 10 / 111\n",
    "CONST_river_value = 9999\n",
    "\n",
    "# critical slope algorithm\n",
    "CONST_critical_slope = 8\n",
    "\n",
    "# for tobler application\n",
    "CONST_elevation_coefficient = 1\n",
    "\n",
    "def slope_coeff(slope):\n",
    "    return 1 / (1 + ((abs(slope) * 100) / CONST_critical_slope) ** 2)\n",
    "\n",
    "def calculate_path_time(value_from, value_to, dist):\n",
    "    rise = (value_to - value_from) / 1000\n",
    "    slope = rise / dist\n",
    "    slope_c = slope_coeff(slope)\n",
    "    time = CONST_speed_day_km * abs(slope_c ** CONST_slope_effect_multiplier)\n",
    "\n",
    "    el_dist = math.sqrt((rise ** 2) + (dist ** 2))\n",
    "    path_time = (el_dist / time)\n",
    "\n",
    "    #print(value_to, value_from, slope, time, el_dist, path_time)\n",
    "    return path_time\n",
    "\n",
    "#print(calculate_path_time(100, 300, 2))\n",
    "#print(calculate_path_time(100, 200, 1))\n",
    "print(calculate_path_time(50, 200, 40))\n",
    "print(calculate_path_time(200, 50, 40))\n",
    "\n",
    "hex_distance = 2 * h3.edge_length(CONST_graph_detail_lvl)\n",
    "print('hex_distance', hex_distance)\n",
    "\n",
    "# load datasets\n",
    "\n",
    "destinations = gpd.read_file(PATH_IN + 'destinations.geojson')\n",
    "\n",
    "rivers_df = gpd.read_file(PATH_IN + 'rivers.geojson') \n",
    "rivers = unary_union(\n",
    "    [river['geometry'] for ri, river in rivers_df.iterrows()]\n",
    ")\n",
    "\n",
    "bridges_df = gpd.read_file(PATH_IN + 'bridges.geojson')\n",
    "bridges = unary_union(\n",
    "    [bridge['geometry'].buffer(hex_distance / 222) for bi, bridge in bridges_df.iterrows()]\n",
    ")\n",
    "\n",
    "bbox = gpd.read_file(PATH_IN + 'bbox.geojson') \n",
    "bb_xy = bbox.total_bounds\n",
    "\n",
    "bounds_json = dict(\n",
    "    geojson.Polygon(\n",
    "        [[\n",
    "            [bb_xy[0], bb_xy[1]],\n",
    "            [bb_xy[0], bb_xy[3]],\n",
    "            [bb_xy[2], bb_xy[3]],\n",
    "            [bb_xy[2], bb_xy[1]],\n",
    "            [bb_xy[0], bb_xy[1]],\n",
    "        ]]\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load elevation\n",
    "\n",
    "elevation = gdal.Open(PATH_IN + 'elevation.tif')\n",
    "band = elevation.GetRasterBand(1)\n",
    "cols = elevation.RasterXSize\n",
    "rows = elevation.RasterYSize\n",
    "\n",
    "transform = elevation.GetGeoTransform()\n",
    "xOrigin = transform[0]\n",
    "yOrigin = transform[3]\n",
    "pixelWidth = transform[1]\n",
    "pixelHeight = -transform[5]\n",
    "\n",
    "elevation_data = band.ReadAsArray(0, 0, cols, rows)\n",
    "\n",
    "# check whether there is river or a bridge\n",
    "def path_value_point (hex_center):\n",
    "    #return elevation_point(hex_center)\n",
    "    #on_river = hex.intersects(rivers)\n",
    "    on_river = hex_center.distance(rivers) < hex_distance / 200\n",
    "    if on_river: \n",
    "        on_bridge = hex_center.distance(bridges) < hex_distance / 200\n",
    "        if not on_bridge:\n",
    "            value = CONST_river_value\n",
    "        else:\n",
    "            value = elevation_point(hex_center)\n",
    "    else:\n",
    "        value = elevation_point(hex_center)\n",
    "    return value\n",
    "\n",
    "# get elevation value for the given geographical point\n",
    "def elevation_point (point):\n",
    "    row = int((yOrigin - point.y ) / pixelHeight)\n",
    "    col = int((point.x - xOrigin) / pixelWidth)\n",
    "    \n",
    "    if elevation_data.shape[0] > row and elevation_data.shape[1] > col:\n",
    "        el_value = int(elevation_data[row][col])\n",
    "        if el_value <= 0: # sea\n",
    "            return CONST_river_value\n",
    "        else:\n",
    "            return el_value\n",
    "    else:\n",
    "        return CONST_river_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Pandas Apply: 100%|██████████| 1711237/1711237 [00:30<00:00, 55494.55it/s]\n",
      "Pandas Apply: 100%|██████████| 1711237/1711237 [02:45<00:00, 10330.65it/s]\n",
      "Pandas Apply: 100%|██████████| 1711237/1711237 [00:48<00:00, 35482.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# construct hexes dataframe\n",
    "\n",
    "hex_ids = list(h3.polyfill(bounds_json, CONST_graph_detail_lvl))\n",
    "\n",
    "hexes_df = pd.DataFrame(hex_ids, columns=['id'])\n",
    "hexes_df['center'] = hexes_df.swifter.apply(\n",
    "    lambda x: Point(h3.h3_to_geo(x['id'])),\n",
    "    axis = 1\n",
    ")\n",
    "hexes_df[\"value\"] = hexes_df.swifter.apply(\n",
    "    lambda x: path_value_point(x['center']),\n",
    "    axis = 1\n",
    ")\n",
    "hexes_df.set_index('id', inplace=True)\n",
    "\n",
    "# find neighboring hexes\n",
    "hexes_df['neighbors'] = hexes_df.swifter.apply(\n",
    "    lambda x: \\\n",
    "        [\n",
    "            h3.get_destination_h3_index_from_unidirectional_edge(n) \n",
    "            for n in h3.get_h3_unidirectional_edges_from_hexagon(x.name)\\\n",
    "        ],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# save hexes_df\n",
    "hexes_df.to_csv(PATH_OUT + 'hexes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      center  value  \\\n",
       "id                                                                    \n",
       "8863a4185bfffff   POINT (14.8745390739082 52.32821401808984)     71   \n",
       "885274069dfffff  POINT (20.19757190887843 48.51922149557049)    306   \n",
       "88524698edfffff   POINT (18.42761199331396 49.7557567142236)    293   \n",
       "885269188bfffff  POINT (18.97688135148771 54.06097202831151)      1   \n",
       "8863b390a5fffff  POINT (12.08361435781251 50.61263651585706)    421   \n",
       "...                                                      ...    ...   \n",
       "8863147805fffff  POINT (15.80935339937383 54.54591998078079)   9999   \n",
       "8852750413fffff  POINT (19.96121564276257 49.49717456188855)    633   \n",
       "885245d1b5fffff  POINT (18.87294493709587 51.19437328851778)    172   \n",
       "885259b4b9fffff  POINT (15.26309842905544 51.99925536277042)     82   \n",
       "8852e0b949fffff  POINT (15.21097314875145 46.10760035189676)    323   \n",
       "\n",
       "                                                         neighbors  \n",
       "id                                                                  \n",
       "8863a4185bfffff  [8863a41ae7fffff, 8863a41859fffff, 8863a41851f...  \n",
       "885274069dfffff  [8852740683fffff, 8852740699fffff, 885274068bf...  \n",
       "88524698edfffff  [88524698e5fffff, 885246983bfffff, 8852469833f...  \n",
       "885269188bfffff  [885269189dfffff, 8852691889fffff, 8852691881f...  \n",
       "8863b390a5fffff  [8863b3919bfffff, 8863b39199fffff, 8863b391d3f...  \n",
       "...                                                            ...  \n",
       "8863147805fffff  [8863147863fffff, 8863147829fffff, 8863147801f...  \n",
       "8852750413fffff  [885275041bfffff, 88527504e9fffff, 88527504cdf...  \n",
       "885245d1b5fffff  [885245c349fffff, 885245d1bdfffff, 885245d1b1f...  \n",
       "885259b4b9fffff  [885259b4bdfffff, 885259b4bbfffff, 885259b4b1f...  \n",
       "8852e0b949fffff  [8852e0bb27fffff, 8852e0bb35fffff, 8852e0bb23f...  \n",
       "\n",
       "[1711237 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>center</th>\n      <th>value</th>\n      <th>neighbors</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8863a4185bfffff</th>\n      <td>POINT (14.8745390739082 52.32821401808984)</td>\n      <td>71</td>\n      <td>[8863a41ae7fffff, 8863a41859fffff, 8863a41851f...</td>\n    </tr>\n    <tr>\n      <th>885274069dfffff</th>\n      <td>POINT (20.19757190887843 48.51922149557049)</td>\n      <td>306</td>\n      <td>[8852740683fffff, 8852740699fffff, 885274068bf...</td>\n    </tr>\n    <tr>\n      <th>88524698edfffff</th>\n      <td>POINT (18.42761199331396 49.7557567142236)</td>\n      <td>293</td>\n      <td>[88524698e5fffff, 885246983bfffff, 8852469833f...</td>\n    </tr>\n    <tr>\n      <th>885269188bfffff</th>\n      <td>POINT (18.97688135148771 54.06097202831151)</td>\n      <td>1</td>\n      <td>[885269189dfffff, 8852691889fffff, 8852691881f...</td>\n    </tr>\n    <tr>\n      <th>8863b390a5fffff</th>\n      <td>POINT (12.08361435781251 50.61263651585706)</td>\n      <td>421</td>\n      <td>[8863b3919bfffff, 8863b39199fffff, 8863b391d3f...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8863147805fffff</th>\n      <td>POINT (15.80935339937383 54.54591998078079)</td>\n      <td>9999</td>\n      <td>[8863147863fffff, 8863147829fffff, 8863147801f...</td>\n    </tr>\n    <tr>\n      <th>8852750413fffff</th>\n      <td>POINT (19.96121564276257 49.49717456188855)</td>\n      <td>633</td>\n      <td>[885275041bfffff, 88527504e9fffff, 88527504cdf...</td>\n    </tr>\n    <tr>\n      <th>885245d1b5fffff</th>\n      <td>POINT (18.87294493709587 51.19437328851778)</td>\n      <td>172</td>\n      <td>[885245c349fffff, 885245d1bdfffff, 885245d1b1f...</td>\n    </tr>\n    <tr>\n      <th>885259b4b9fffff</th>\n      <td>POINT (15.26309842905544 51.99925536277042)</td>\n      <td>82</td>\n      <td>[885259b4bdfffff, 885259b4bbfffff, 885259b4b1f...</td>\n    </tr>\n    <tr>\n      <th>8852e0b949fffff</th>\n      <td>POINT (15.21097314875145 46.10760035189676)</td>\n      <td>323</td>\n      <td>[8852e0bb27fffff, 8852e0bb35fffff, 8852e0bb23f...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1711237 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "hexes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create weighted non-directional graph for all combinations of neighboring hexes\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "hexes_df = gpd.read_file(\n",
    "    PATH_OUT + 'hexes.csv'\n",
    ")\n",
    "hexes_df['center'] = hexes_df['center'].apply(wkt.loads)\n",
    "hexes_df['neighbors'] = hexes_df['neighbors'].apply(literal_eval)\n",
    "hexes_df[\"value\"] = pd.to_numeric(hexes_df[\"value\"])\n",
    "hexes_df.set_index('id', inplace=True)\n",
    "\n",
    "g = nk.Graph(directed=False, weighted=True)\n",
    "\n",
    "hexes_df['node'] = hexes_df.apply(\n",
    "    lambda x: g.addNode(),\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# node_id -> hex_id shorthand dictionary\n",
    "node_to_hex = {node_id: hex_id for (hex_id, node_id) in hexes_df[['node']].itertuples()}\n",
    "\n",
    "for (hex_from_id, value_from, node_from, neighbors) in hexes_df[['value', 'node', 'neighbors']].itertuples():\n",
    "    for hex_to_id in neighbors:\n",
    "        if hex_to_id in hexes_df.index:\n",
    "            node_to = hexes_df.at[hex_to_id, 'node']\n",
    "            value_to = hexes_df.at[hex_to_id, 'value']\n",
    "            g.addEdge(node_from, node_to, calculate_path_time(value_from, value_to, hex_distance))\n",
    "\n",
    "g.indexEdges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run dijkstra algorithm for all destinations\n",
    "\n",
    "destinations['hex_id'] = destinations.apply(\n",
    "    lambda x: h3.geo_to_h3(x['geometry'].x, x['geometry'].y, CONST_graph_detail_lvl),\n",
    "    axis=1\n",
    ")\n",
    "destinations['node_id'] = destinations.apply(\n",
    "    lambda x: hexes_df.at[x['hex_id'], 'node'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# def calculate_paths(hex_id):\n",
    "#     dij = nk.distance.Dijkstra(g, hexes_df.at[hex_id, 'node'], True, False)\n",
    "#     dij.run()\n",
    "#     return dij\n",
    "\n",
    "# destinations['dij'] = destinations.swifter.apply(\n",
    "#     lambda x: calculate_paths(x['hex_id']),\n",
    "#     axis=1\n",
    "# )\n",
    "#destinations.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "finding paths for destinations 0/128 (0%)\n",
      "finding paths for destinations 1/128 (0%)\n",
      "finding paths for destinations 2/128 (1%)\n",
      "finding paths for destinations 3/128 (2%)\n",
      "finding paths for destinations 4/128 (3%)\n",
      "finding paths for destinations 5/128 (3%)\n",
      "finding paths for destinations 6/128 (4%)\n",
      "finding paths for destinations 7/128 (5%)\n",
      "finding paths for destinations 8/128 (6%)\n",
      "finding paths for destinations 9/128 (7%)\n",
      "finding paths for destinations 10/128 (7%)\n",
      "finding paths for destinations 11/128 (8%)\n",
      "finding paths for destinations 12/128 (9%)\n",
      "finding paths for destinations 13/128 (10%)\n",
      "finding paths for destinations 14/128 (10%)\n",
      "finding paths for destinations 15/128 (11%)\n",
      "finding paths for destinations 16/128 (12%)\n",
      "finding paths for destinations 17/128 (13%)\n",
      "finding paths for destinations 18/128 (14%)\n",
      "finding paths for destinations 19/128 (14%)\n",
      "finding paths for destinations 20/128 (15%)\n",
      "finding paths for destinations 21/128 (16%)\n",
      "finding paths for destinations 22/128 (17%)\n",
      "finding paths for destinations 23/128 (17%)\n",
      "finding paths for destinations 24/128 (18%)\n",
      "finding paths for destinations 25/128 (19%)\n",
      "finding paths for destinations 26/128 (20%)\n",
      "finding paths for destinations 27/128 (21%)\n",
      "finding paths for destinations 28/128 (21%)\n",
      "finding paths for destinations 29/128 (22%)\n",
      "finding paths for destinations 30/128 (23%)\n",
      "finding paths for destinations 31/128 (24%)\n",
      "finding paths for destinations 32/128 (25%)\n",
      "finding paths for destinations 33/128 (25%)\n",
      "finding paths for destinations 34/128 (26%)\n",
      "finding paths for destinations 35/128 (27%)\n",
      "finding paths for destinations 36/128 (28%)\n",
      "finding paths for destinations 37/128 (28%)\n",
      "finding paths for destinations 38/128 (29%)\n",
      "finding paths for destinations 39/128 (30%)\n",
      "finding paths for destinations 40/128 (31%)\n",
      "finding paths for destinations 41/128 (32%)\n",
      "finding paths for destinations 42/128 (32%)\n",
      "finding paths for destinations 43/128 (33%)\n",
      "finding paths for destinations 44/128 (34%)\n",
      "finding paths for destinations 45/128 (35%)\n",
      "finding paths for destinations 46/128 (35%)\n",
      "finding paths for destinations 47/128 (36%)\n",
      "finding paths for destinations 48/128 (37%)\n",
      "finding paths for destinations 49/128 (38%)\n",
      "finding paths for destinations 50/128 (39%)\n",
      "finding paths for destinations 51/128 (39%)\n",
      "finding paths for destinations 52/128 (40%)\n",
      "finding paths for destinations 53/128 (41%)\n",
      "finding paths for destinations 54/128 (42%)\n",
      "finding paths for destinations 55/128 (42%)\n",
      "finding paths for destinations 56/128 (43%)\n",
      "finding paths for destinations 57/128 (44%)\n",
      "finding paths for destinations 58/128 (45%)\n",
      "finding paths for destinations 59/128 (46%)\n",
      "finding paths for destinations 60/128 (46%)\n",
      "finding paths for destinations 61/128 (47%)\n",
      "finding paths for destinations 62/128 (48%)\n",
      "finding paths for destinations 63/128 (49%)\n",
      "finding paths for destinations 64/128 (50%)\n",
      "finding paths for destinations 65/128 (50%)\n",
      "finding paths for destinations 66/128 (51%)\n",
      "finding paths for destinations 67/128 (52%)\n",
      "finding paths for destinations 68/128 (53%)\n",
      "finding paths for destinations 69/128 (53%)\n",
      "finding paths for destinations 70/128 (54%)\n",
      "finding paths for destinations 71/128 (55%)\n",
      "finding paths for destinations 72/128 (56%)\n",
      "finding paths for destinations 73/128 (57%)\n",
      "finding paths for destinations 74/128 (57%)\n",
      "finding paths for destinations 75/128 (58%)\n",
      "finding paths for destinations 76/128 (59%)\n",
      "finding paths for destinations 77/128 (60%)\n",
      "finding paths for destinations 78/128 (60%)\n",
      "finding paths for destinations 79/128 (61%)\n",
      "finding paths for destinations 80/128 (62%)\n",
      "finding paths for destinations 81/128 (63%)\n",
      "finding paths for destinations 82/128 (64%)\n",
      "finding paths for destinations 83/128 (64%)\n",
      "finding paths for destinations 84/128 (65%)\n",
      "finding paths for destinations 85/128 (66%)\n",
      "finding paths for destinations 86/128 (67%)\n",
      "finding paths for destinations 87/128 (67%)\n",
      "finding paths for destinations 88/128 (68%)\n",
      "finding paths for destinations 89/128 (69%)\n",
      "finding paths for destinations 90/128 (70%)\n",
      "finding paths for destinations 91/128 (71%)\n",
      "finding paths for destinations 92/128 (71%)\n",
      "finding paths for destinations 93/128 (72%)\n",
      "finding paths for destinations 94/128 (73%)\n",
      "finding paths for destinations 95/128 (74%)\n",
      "finding paths for destinations 96/128 (75%)\n",
      "finding paths for destinations 97/128 (75%)\n",
      "finding paths for destinations 98/128 (76%)\n",
      "finding paths for destinations 99/128 (77%)\n",
      "finding paths for destinations 100/128 (78%)\n",
      "finding paths for destinations 101/128 (78%)\n",
      "finding paths for destinations 102/128 (79%)\n",
      "finding paths for destinations 103/128 (80%)\n",
      "finding paths for destinations 104/128 (81%)\n",
      "finding paths for destinations 105/128 (82%)\n",
      "finding paths for destinations 106/128 (82%)\n",
      "finding paths for destinations 107/128 (83%)\n",
      "finding paths for destinations 108/128 (84%)\n",
      "finding paths for destinations 109/128 (85%)\n",
      "finding paths for destinations 110/128 (85%)\n",
      "finding paths for destinations 111/128 (86%)\n",
      "finding paths for destinations 112/128 (87%)\n",
      "finding paths for destinations 113/128 (88%)\n",
      "finding paths for destinations 114/128 (89%)\n",
      "finding paths for destinations 115/128 (89%)\n",
      "finding paths for destinations 116/128 (90%)\n",
      "finding paths for destinations 117/128 (91%)\n",
      "finding paths for destinations 118/128 (92%)\n",
      "finding paths for destinations 119/128 (92%)\n",
      "finding paths for destinations 120/128 (93%)\n",
      "finding paths for destinations 121/128 (94%)\n",
      "finding paths for destinations 122/128 (95%)\n",
      "finding paths for destinations 123/128 (96%)\n",
      "finding paths for destinations 124/128 (96%)\n",
      "finding paths for destinations 125/128 (97%)\n",
      "finding paths for destinations 126/128 (98%)\n",
      "finding paths for destinations 127/128 (99%)\n"
     ]
    }
   ],
   "source": [
    "# calculate hex id for each destination\n",
    "\n",
    "paths = []\n",
    "\n",
    "for (id_from, name_from, hex_from, node_from) in destinations[['name', 'hex_id', 'node_id']].itertuples():\n",
    "\n",
    "    print('finding paths for destinations {}/{} ({}%)'.format(id_from, len(destinations), int(id_from / len(destinations) * 100)))\n",
    "\n",
    "    dij = nk.distance.Dijkstra(g, node_from, True, False)\n",
    "    dij.run()\n",
    "    for (id_to, name_to, hex_to, node_to) in destinations[['name', 'hex_id', 'node_id']].itertuples():\n",
    "         \n",
    "\n",
    "        dist = dij.distance(node_to)\n",
    "        path = dij.getPath(node_to)\n",
    "        path_hexes = LineString([hexes_df.at[node_to_hex[i], 'center'] for i in path])\n",
    "\n",
    "        paths.append(\n",
    "            {\n",
    "                \"from\": name_from,\n",
    "                \"to\": name_to,\n",
    "                \"dist\": dist,\n",
    "                \"geometry\": path_hexes\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ERROR:fiona._env:/home/adam/projects/itinerary-analysis_premysl-otakar/src/processing/../../data/03_paths/paths.geojson: No such file or directory\n",
      "WARNING:fiona._env:driver GeoJSON does not support creation option ENCODING\n"
     ]
    }
   ],
   "source": [
    "# export paths\n",
    "\n",
    "paths_df = gpd.GeoDataFrame(paths, crs=\"epsg:4326\")\n",
    "# simplify geometries\n",
    "paths_df['geometry'] = paths_df.apply(\n",
    "      lambda x: wkt.loads(\n",
    "          wkt.dumps(\n",
    "              x['geometry'].simplify(0.01, preserve_topology=True), \n",
    "              rounding_precision=3\n",
    "            )\n",
    "        ),\n",
    "      axis=1\n",
    "  )\n",
    "#paths_df.to_file(PATH_OUT + 'paths.shp', driver=\"ESRI Shapefile\", encoding=\"utf-8\")\n",
    "paths_df.to_file(PATH_OUT + 'paths.geojson', driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8.677852465148167\n8.67785246514818\n"
     ]
    }
   ],
   "source": [
    "# create a destination metrix table\n",
    "\n",
    "paths_text = \"\".join([line.strip() for line in open(PATH_OUT + 'paths.geojson')])\n",
    "paths_dict = json.loads(paths_text)\n",
    "\n",
    "origins = {}\n",
    "for fi, feat in enumerate(paths_dict['features']):\n",
    "    orig = feat['properties']['from'] \n",
    "    origins[orig] = {'origin': orig}\n",
    "\n",
    "for fi, feat in enumerate(paths_dict['features']):\n",
    "    orig = feat['properties']['from']\n",
    "    dest = feat['properties']['to']\n",
    "    dist = feat['properties']['dist']\n",
    "    origins[orig][dest] = dist\n",
    "\n",
    "dist_df = pd.DataFrame(origins.values())\n",
    "\n",
    "\n",
    "dist_df.set_index('origin', inplace=True)\n",
    "dist_df.to_csv(PATH_OUT + 'dist_m.csv')\n",
    "\n",
    "print(dist_df.at['Brno', 'Praha'])\n",
    "print(dist_df.at['Praha', 'Brno'])\n"
   ]
  }
 ]
}